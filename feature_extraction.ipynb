{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Feb 28 19:55:26 2019\n",
    "\n",
    "@author: ericl\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    #These two dir are used to track the name of the files we want to convert, as only 200 test audios were selected, we track them from\n",
    "    # the ones generated with matlab\n",
    "    clean_train_folder = './Noise_Addition/timit_128/train'\n",
    "    clean_test_folder='./Noise_Addition/timit_128/test'\n",
    "\n",
    "    #These are the folders where we have our noisy data stored\n",
    "    noisy_test_folder = './Noise_Addition/results/test'\n",
    "    noisy_train_folder = './Noise_Addition/results/train'\n",
    "\n",
    "    #output stft features in numpy form and save in below %dirs\n",
    "    output_folder = './features'\n",
    "    output_test_folder='./features/test'\n",
    "    output_train_folder='./features/train'\n",
    "\n",
    "    #the type of noise and SNR we want to deal with, add in dirs to ensure consistency\n",
    "    noisy_types=['babble','white','alarm','destroyerengine']\n",
    "    SNRs=['5dB','10dB','15dB','20dB','0dB','-5dB']\n",
    "\n",
    "else:\n",
    "    #These two dir are used to track the name of the files we want to convert, as only 200 test audios were selected, we track them from\n",
    "    # the ones generated with matlab\n",
    "    clean_train_folder = r'.\\Noise_Addition\\timit_128\\timit\\train'\n",
    "    clean_test_folder=r'.\\Noise_Addition\\timit_128\\timit\\test'\n",
    "\n",
    "    #These are the folders where we have our noisy data stored\n",
    "    noisy_test_folder = r'.\\Noise_Addition\\results\\test'\n",
    "    noisy_train_folder = r'.\\Noise_Addition\\results\\train'\n",
    "\n",
    "    #output stft features in numpy form and save in below dirs\n",
    "    output_folder=r'.\\features'\n",
    "    output_test_folder=r'.\\features\\test'\n",
    "    output_train_folder=r'.\\features\\train'\n",
    "\n",
    "    #the type of noise and SNR we want to deal with, add in dirs to ensure consistency\n",
    "    noisy_types=[r'\\babble',r'\\white',r'\\factory1',r'\\hfchannel']\n",
    "    SNRs=[r'\\5db',r'\\10db',r'\\15db',r'\\20db',r'\\0db',r'\\-5db']\n",
    "    #SNRs=[r'\\5db']\n",
    "    #noisy_types=[r'\\babble']\n",
    "\n",
    "\n",
    "window_size = 2 ** 14  # about 1 second of samples\n",
    "#sample_rate = 16000\n",
    "\n",
    "\n",
    "def saveConvert_info(file):\n",
    "    \"\"\"\n",
    "    input a wav file, return np array after stft\n",
    "    \"\"\"\n",
    "    \n",
    "    y, fs = librosa.load(file, sr=8000)\n",
    "    D = librosa.core.stft(y, n_fft = 128)\n",
    "    #sample_rate, samples = wavfile.read(file)\n",
    "    #x=scipy.signal.stft(samples,sample_rate)\n",
    "    D_a = np.abs(D)\n",
    "    D_db = librosa.core.amplitude_to_db(D_a, ref=np.max)\n",
    "    phase=np.angle(D)\n",
    "    max_value=np.max(D_a)\n",
    "    return [D_db, phase, max_value]\n",
    "\n",
    "def saveConvert_data(file):\n",
    "    \"\"\"\n",
    "    input a wav file, return np array after stft\n",
    "    \"\"\"\n",
    "    y, fs = librosa.load(file, sr=8000)\n",
    "    D = librosa.core.stft(y, n_fft = 128)\n",
    "    D_a = np.abs(D)\n",
    "\n",
    "    D_db = librosa.core.amplitude_to_db(D_a, ref=np.max)\n",
    "    return D_db\n",
    "    \n",
    "\n",
    "def normalize(data):\n",
    "    \"\"\"\n",
    "    normalize data by each row\n",
    "    \n",
    "    intype: np array (n_fft // 2 + 1) * n\n",
    "    rtype: np array (n_fft // 2 + 1) * n\n",
    "    \n",
    "    \"\"\"\n",
    "    #this function should not be utilized until we get the mean and std of our data\n",
    "    return (data-np.mean(data,axis=1).reshape(-1, 1)) / np.std(data,axis=1).reshape(-1, 1)\n",
    "\n",
    "test_dict={}\n",
    "def processData(data_type):\n",
    "    \"\"\"\n",
    "    Serialize, down-sample the sliced signals and save on separate folder.\n",
    "    \"\"\"\n",
    "    mean=np.array([])\n",
    "    count=0\n",
    "\n",
    "    #Generate features for clean data\n",
    "    max_indices = []\n",
    "    if data_type == 'train':\n",
    "        output_clean_folder = os.path.join(output_train_folder, 'clean')\n",
    "        if not os.path.exists(output_clean_folder):\n",
    "            os.makedirs(output_clean_folder)\n",
    "        for root, dirs, files in os.walk(clean_train_folder):\n",
    "            for filename in tqdm_notebook(files, desc='Converting {} audios'.format(data_type)):\n",
    "                if '.wav' in filename:\n",
    "                    clean_file = os.path.join(clean_train_folder, filename)\n",
    "                    data = saveConvert_data(clean_file)\n",
    "                    np.save(os.path.join(output_clean_folder, '{}'.format(filename)), data)\n",
    "                    max_indices.append((filename, data.shape[1]))\n",
    "    df = pd.DataFrame(max_indices, columns=[\"filename\",\"max_idx\"])\n",
    "    df.to_csv(os.path.join(output_folder, 'list.csv'), index=False)\n",
    "    \n",
    "    \n",
    "    for snr in SNRs:\n",
    "        for noise in noisy_types:\n",
    "            \n",
    "            if data_type == 'train':\n",
    "                clean_folder = clean_train_folder\n",
    "                noisy_folder = os.path.join(noisy_train_folder, noise, snr)\n",
    "                serialized_folder = os.path.join(output_train_folder, noise, snr)\n",
    "            else:\n",
    "                clean_folder = clean_test_folder\n",
    "                noisy_folder = os.path.join(noisy_test_folder, noise, snr)\n",
    "                serialized_folder = os.path.join(output_test_folder, noise, snr)\n",
    "            if not os.path.exists(serialized_folder):\n",
    "                os.makedirs(serialized_folder)\n",
    "            \n",
    "            for root, dirs, files in os.walk(clean_folder):\n",
    "                for filename in tqdm_notebook(files, desc='Converting {} audios'.format(data_type)):\n",
    "                    if '.wav' in filename:\n",
    "                        noisy_file = os.path.join(noisy_folder, filename)\n",
    "                        \n",
    "                        #get the mean\n",
    "                        if data_type == 'train':\n",
    "                            converted_noisy=saveConvert_data(noisy_file)\n",
    "                            if len(mean) == 0:\n",
    "                                mean = np.sum(converted_noisy,axis=1)\n",
    "                            else:\n",
    "                                mean += np.sum(converted_noisy,axis=1)\n",
    "\n",
    "                            count += len(converted_noisy[0])\n",
    "\n",
    "                            np.save(os.path.join(serialized_folder, '{}'.format(filename)), arr=converted_noisy)\n",
    "                        else:\n",
    "                            data, phase, max_value = saveConvert_info(noisy_file)\n",
    "                            data_info = [()]\n",
    "                            data_info[()]['data'] = data\n",
    "                            data_info[()]['phase'] = phase\n",
    "                            data_info[()]['max_value'] = max_value\n",
    "                            np.save(os.path.join(serialized_folder, '{}'.format(filename)), arr=data_info)\n",
    "                            \n",
    "    mean = mean / count\n",
    "    np.save('mean.npy',mean)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43d28c8588c4fb2af0c944bc3aa8f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting train audios', max=4620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d83b99935f482cb049691f9cc41446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting train audios', max=4620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948fb0af0ca9413cb579a10b1d69dbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting train audios', max=4620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b656750f7194aa489863e788a736c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting train audios', max=4620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa8244274224d10aeff66a17555a289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting train audios', max=4620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8d4239c4254606af75d41658837312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting train audios', max=4620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b510f63e7c14869835147776eabea90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting train audios', max=4620), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "77805 requested and 52192 written",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0b9bcdd547f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocessData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-7953dd568bc4>\u001b[0m in \u001b[0;36mprocessData\u001b[0;34m(data_type)\u001b[0m\n\u001b[1;32m    154\u001b[0m                             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_noisy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverted_noisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveConvert_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m--> 521\u001b[0;31m                            pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             for chunk in numpy.nditer(\n",
      "\u001b[0;31mOSError\u001b[0m: 77805 requested and 52192 written"
     ]
    }
   ],
   "source": [
    "processData('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get the mean and std for each feature, and then feed in normalized ones only in the traininig process, done by pytorch\n",
    "def get_std(data_type):\n",
    "    \"\"\"\n",
    "    Serialize, down-sample the sliced signals and save on separate folder.\n",
    "    \"\"\"\n",
    "    data=np.array([])\n",
    "    for snr in SNRs:\n",
    "        for noise in noisy_types:\n",
    "            #max_idxs=[]\n",
    "            \n",
    "            if data_type == 'train':\n",
    "                clean_folder = clean_train_folder\n",
    "                noisy_folder = noisy_train_folder+noise+snr\n",
    "                serialized_folder = serialized_train_folder+noise+snr\n",
    "            else:\n",
    "                clean_folder = clean_test_folder\n",
    "                noisy_folder = noisy_test_folder+noise+snr\n",
    "                serialized_folder = serialized_test_folder+noise+snr\n",
    "            if not os.path.exists(serialized_folder):\n",
    "                os.makedirs(serialized_folder)\n",
    "            \n",
    "            #clean_folder = clean_test_folder\n",
    "            #noisy_folder = noisy_test_folder+noise+snr\n",
    "            phase_max=0\n",
    "            phase_min=0\n",
    "            \n",
    "            for root, dirs, files in os.walk(clean_folder):\n",
    "                if len(files) == 0:\n",
    "                    continue\n",
    "                #print('current folder',dirs)\n",
    "                for filename in tqdm_notebook(files, desc='Converting {} audios'.format(data_type)):\n",
    "                    noisy_file = os.path.join(noisy_folder, filename)\n",
    "                    if '.wav' in filename:\n",
    "                        if len(data)==0:\n",
    "                            data=saveConvert_data(noisy_file)\n",
    "                        else:\n",
    "                            data=np.hstack((data,saveConvert_data(noisy_file)))\n",
    "\n",
    "\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting s audios: 100%|██████████████████████████████████████████████████████████| 201/201 [00:01<00:00, 159.55it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:03<00:00, 54.32it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:05<00:00, 36.27it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:07<00:00, 27.62it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:08<00:00, 22.49it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:10<00:00, 18.56it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:12<00:00, 15.78it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:14<00:00, 13.92it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:16<00:00, 12.32it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:23<00:00,  8.64it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:19<00:00, 10.15it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:24<00:00,  8.22it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:24<00:00,  8.27it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:25<00:00,  8.03it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:26<00:00,  7.49it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:28<00:00,  7.12it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:29<00:00,  6.79it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:31<00:00,  6.39it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:33<00:00,  6.05it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:34<00:00,  5.75it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:36<00:00,  5.50it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:38<00:00,  5.24it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:40<00:00,  5.02it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:41<00:00,  4.80it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:43<00:00,  4.58it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:45<00:00,  4.43it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:47<00:00,  4.26it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:49<00:00,  4.07it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:50<00:00,  4.01it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:51<00:00,  3.88it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:53<00:00,  3.77it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:54<00:00,  3.66it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [00:57<00:00,  3.48it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [01:00<00:00,  3.30it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [01:01<00:00,  3.27it/s]\n",
      "Converting s audios: 100%|███████████████████████████████████████████████████████████| 201/201 [01:02<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "data=get_std('s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
