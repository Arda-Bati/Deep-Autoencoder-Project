{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from TIMIT_dataloader_DAE import prepareTIMIT_train\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n"
     ]
    }
   ],
   "source": [
    "num_frames = 11\n",
    "batch_size = 256         # Number of samples in each minibatch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 8, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "train_loader, val_loader = prepareTIMIT_train(batch_size = batch_size, \n",
    "                                              num_frames = num_frames, \n",
    "                                              shuffle = True,\n",
    "                                              seed = 1,\n",
    "                                              extras=extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size, \n",
    "                 num_layers = 1, \n",
    "                 tied = True,\n",
    "                 batch_normalization = False):\n",
    "        \n",
    "        super(AE, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.tied = tied\n",
    "        self.batch_normalization = batch_normalization\n",
    "        \n",
    "        self.W1 = nn.Parameter(torch.randn(hidden_size, input_size).float() * 0.1)\n",
    "        self.W2 = nn.Parameter(torch.randn(input_size, hidden_size).float() * 0.1)\n",
    "        self.b = nn.Parameter(torch.randn(hidden_size).float() * 0.01)\n",
    "        self.c = nn.Parameter(torch.randn(input_size).float() * 0.01)\n",
    "        \n",
    "        self.normed = nn.BatchNorm1d(hidden_size)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            batch = F.linear(batch, self.W1, bias = self.b)\n",
    "            if self.batch_normalization:\n",
    "                batch = self.normed(batch)\n",
    "            batch = F.sigmoid(batch)\n",
    "            if self.tied:\n",
    "                batch = F.linear(batch, weight = self.W1.t(), bias = self.c)\n",
    "            else:\n",
    "                batch = F.linear(batch, weight = self.W2, bias = self.c)\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size as dimension of features, hidden size is # hidden unit, and number of classes is the dimension of dictionary\n",
    "input_size = num_frames * 65\n",
    "hidden_size = 500\n",
    "num_layers = 3\n",
    "\n",
    "model = AE(input_size = input_size, \n",
    "           hidden_size = hidden_size,\n",
    "           num_layers = num_layers,\n",
    "           tied = True,\n",
    "           batch_normalization = False)\n",
    "model = model.to(computing_device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "criterion = criterion.to(computing_device)\n",
    "\n",
    "criterion_val = nn.MSELoss(reduction='sum')\n",
    "criterion_val = criterion_val.to(computing_device)\n",
    "\n",
    "learning_rate = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, val_loader):\n",
    "\n",
    "    full_val_loss = 0.0\n",
    "    count = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for minibatch_count, (input, target) in enumerate(val_loader, 0):\n",
    "\n",
    "            batch_size, _  = input.shape\n",
    "            \n",
    "            input = input.to(computing_device)\n",
    "            target = target.to(computing_device)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            full_val_loss += loss\n",
    "            count += batch_size\n",
    "    \n",
    "    avg_loss = full_val_loss / count\n",
    "    scheduler.step(avg_loss)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba522b7d4f847d98516a215e6bd91dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64532), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/03/103/m3liang/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0. Training loss: 8.234919548034668\n",
      "Minibatch: 100. Training loss: 2.0578396320343018\n",
      "Minibatch: 200. Training loss: 1.6882438659667969\n",
      "Minibatch: 300. Training loss: 1.5711473226547241\n",
      "Minibatch: 400. Training loss: 1.5212535858154297\n",
      "Minibatch: 500. Training loss: 1.4884471893310547\n",
      "Minibatch: 600. Training loss: 1.408820629119873\n",
      "Minibatch: 700. Training loss: 1.4083874225616455\n",
      "Minibatch: 800. Training loss: 1.3829267024993896\n",
      "Minibatch: 900. Training loss: 1.5335625410079956\n",
      "Minibatch: 1000. Training loss: 1.3733969926834106\n",
      "Minibatch: 1100. Training loss: 1.2891660928726196\n",
      "Minibatch: 1200. Training loss: 1.2946466207504272\n",
      "Minibatch: 1300. Training loss: 1.2337327003479004\n",
      "Minibatch: 1400. Training loss: 1.2261452674865723\n",
      "Minibatch: 1500. Training loss: 1.2036327123641968\n",
      "Minibatch: 1600. Training loss: 1.2563279867172241\n",
      "Minibatch: 1700. Training loss: 1.2935760021209717\n",
      "Minibatch: 1800. Training loss: 1.2877683639526367\n",
      "Minibatch: 1900. Training loss: 1.2421594858169556\n",
      "Minibatch: 2000. Training loss: 1.204660177230835\n"
     ]
    }
   ],
   "source": [
    "# clip = 1.0\n",
    "epochs_number = 100\n",
    "sample_history = []\n",
    "best_val_loss = float(\"inf\")\n",
    "loss_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch_number in range(epochs_number):   \n",
    "\n",
    "    N = 100\n",
    "    \n",
    "    for minibatch_count, (input, target) in enumerate(tqdm_notebook(train_loader), 0):\n",
    "        model.train()\n",
    "        \n",
    "        input = input.float()\n",
    "        target = target.float()\n",
    "        input = input.to(computing_device)\n",
    "        target = target.to(computing_device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss_list.append(loss)\n",
    "        loss.backward()\n",
    "    \n",
    "        if minibatch_count % N == 0:\n",
    "            print('Minibatch: {}. Training loss: {}'.format(minibatch_count, loss))\n",
    "    \n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch_number % N == 0: \n",
    "        current_val_loss = validate(model, criterion_val, val_loader)\n",
    "        print('epoch: {}. Training loss: {}, Val loss: {}'.format(epoch_number, \n",
    "                                                                  loss,\n",
    "                                                                  current_val_loss))\n",
    "        val_loss_list.append(current_val_loss)\n",
    "    \n",
    "    else:\n",
    "        print('epoch: {}. Training loss: {}'.format(epoch_number, loss))\n",
    "    \n",
    "    \n",
    "    if current_val_loss < best_val_loss :        \n",
    "        torch.save(model.state_dict(), 'music_lstm.pt')\n",
    "        best_val_loss = current_val_loss\n",
    "        \n",
    "torch.save((loss_list, val_loss_list), './losses.pt')\n",
    "plt.figure()\n",
    "plt.plot(range(len(loss_list)), loss_list, label='Training Loss')\n",
    "plt.plot(range(0, len(val_loss_list) * N * minibatch_count, N * minibatch_count) , val_loss_list, label='Vadiation Loss')\n",
    "plt.xlabel('minibatches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
